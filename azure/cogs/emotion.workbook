---
uti: com.xamarin.workbook
platforms:
- iOS
packages:
- id: Newtonsoft.Json
  version: 8.0.3
---

# Azure Cognitive Services

Imaage analysis with the Cognitive Services' `EmotionServiceClient`

We‚Äôve started by adding the `Microsoft.ProjectOxford.Emotion` NuGet to the iOS Workbook. The references are loaded into the workbook.

```csharp
#r "System.Collections"
#r "Newtonsoft.Json"
//#r "Microsoft.ProjectOxford.Common"
//#r "Microsoft.ProjectOxford.Emotion"
```

We first define a simple data structure to model an employee. Remote properties will be populated from Azure. We define a couple of local properties as well that we‚Äôll need later.

```csharp
using Newtonsoft.Json;

public class Acquaintance
{
	public string FirstName { get; set; }
	public string LastName { get; set; }
	public string Company { get; set; }
	public string JobTitle { get; set; }
	public string Email { get; set; }
	public string Phone { get; set; }
	public string Street { get; set; }
	public string City{ get; set; }
	public string PostalCode { get; set; }
	public string State { get; set; }
	public string PhotoUrl { get; set; }
	public override string ToString () {
		return $"{FirstName} {LastName} ({JobTitle}) " + (AvatarImage == null?"‚ö™Ô∏è":"‚òëÔ∏è");
	}
	// client-local properties
	[JsonIgnore] public float Happiness { get; set; }
	[JsonIgnore] public UIImage AvatarImage { get; set; }
}
```

The list is populated from another sample‚Äôs [seed data](https://github.com/xamarinhq/app-acquaint/blob/2ca9e83c8344d35288e4ea7868ea6e5795a25e9c/App/Common/Acquaint.Data/SeedData.cs).

```csharp
#load "index.csx"

var employees = SeedData.Get();
```

Here we fetch the avatar images for each person and cache them back on the model object. Inspecting the `employees` list now shows happy faces!

```csharp
foreach (var employee in employees) {
	var imageData = NSData.FromUrl (new NSUrl (employee.PhotoUrl));
	if (imageData != null)
		employee.AvatarImage = UIImage.LoadFromData (imageData);
}

employees
```

## Cognitive Services

For some real fun, we can analyze employee emotions using the Emotions API from [Microsoft Cognitive Services](https://www.microsoft.com/cognitive-services). We have provided our API key in the *emotion.key* file.

```csharp
using System.IO;
using Microsoft.ProjectOxford.Emotion;

var emotionClient = new EmotionServiceClient ("YOUR_EMOTION_SERVICE_KEY_HERE");
```

Let‚Äôs see if we can make sense of our first employee‚Äôs emotions by analyzing their avatar photo. The Emotion service will fetch the avatar from a URL in this case, but it can also process raw image data sent directly from the client.

```csharp
await emotionClient.RecognizeAsync (employees.First ().avatarUrl)
```

As we can see, the Emotion API provides an estimation of overall happiness. Let‚Äôs perform the same analysis for all of our employees and record their happiness. If the service cannot detect a human face, it will return no scores.

```csharp
foreach (var employee in employees) {
	var emotionData = await emotionClient.RecognizeAsync (employee.avatarUrl);
	employee.Happiness = (emotionData.FirstOrDefault ()?.Scores?.Happiness).GetValueOrDefault ();
}

employees
```

We want our least happy employees to show up first...

```csharp
employees = employees.OrderBy (x => x.Happiness).ToList ()
```

## Bringing it together on iOS

Now we‚Äôll explore rendering our data in a UITableView so we can interact with it live in the iOS simulator.

```csharp
class EmployeeTableSource : UITableViewDataSource
{
	public override nint RowsInSection (UITableView tableview, nint section)
		=> employees.Count;

	public override UITableViewCell GetCell (UITableView tableView, NSIndexPath indexPath)
	{
		var employee = employees [indexPath.Row];

		string emoji;

		if (employee.Happiness >= 0.9) {
			emoji = "üòÄ";
		} else if (employee.Happiness >= 0.8) {
			emoji = "üôÇ";
		} else if (employee.Happiness >= 0.4) {
			emoji = "üòï";
		} else if (employee.Happiness == 0) {
			emoji = "üê∂";
		} else {
			emoji = "üò°";
		}

		return new UITableViewCell (UITableViewCellStyle.Subtitle, "MyTableCell") {
			TextLabel  = { Text = $"{employee.firstName} {employee.lastName}" },
			DetailTextLabel = { Text = $"{employee.Happiness:P} {emoji}" },
			ImageView = { Image = employee.AvatarImage }
		};
	}
}
```

```csharp
KeyWindow.RootViewController = new UINavigationController (new UITableViewController {
	Title = "Happiness Training Candidates",
	TableView = { DataSource = new EmployeeTableSource () }
})
```

----
### Exercises

* Change the background color of the `UITableViewCell` based on the happiness of the employee.

* The Emotions API covers more than just happiness. Try adding information about anger, available in `emotionData`.

* Implement a custom `UITableViewCell` that shows all emotion data.
----
